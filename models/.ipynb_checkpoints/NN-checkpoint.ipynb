{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cb238c2b5d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtcl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleak\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mleak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.layers as tcl\n",
    "import numpy as np\n",
    "\n",
    "def leaky_relu(x, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * x + f2 * tf.abs(x)\n",
    "\n",
    "\n",
    "class NeuralNet(object):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hypers = {\n",
    "            'learning_rate': 0.003, 'hidden_units': 128, 'batch_size': 128,\n",
    "            'max_iters': 100000, 'eval_iters': 1000}\n",
    "\n",
    "        self._contruct_model()\n",
    "        self._init_sess()\n",
    "\n",
    "    def _contruct_model(self):\n",
    "        self.input_data = tf.placeholder(\n",
    "            shape=[None, self.in_dim], dtype=tf.float32)\n",
    "        self.labels = tf.placeholder(shape=[None, ], dtype=tf.int32)\n",
    "        self.one_hot_labels = tf.one_hot(\n",
    "            indices=self.labels, depth=2, on_value=1.0, off_value=0.0)\n",
    "        h1 = tcl.fully_connected(\n",
    "            inputs=self.input_data,\n",
    "            num_outputs=self.hypers['hidden_units'],\n",
    "            weights_regularizer=tcl.l2_regularizer(0.01),\n",
    "            activation_fn=leaky_relu)\n",
    "        h2 = tcl.fully_connected(\n",
    "            inputs=h1, num_outputs=self.hypers['hidden_units'],\n",
    "            weights_regularizer=tcl.l2_regularizer(0.01),\n",
    "            activation_fn=leaky_relu)\n",
    "        self.logits = tcl.fully_connected(\n",
    "            inputs=h2, num_outputs=self.out_dim,\n",
    "            weights_regularizer=tcl.l2_regularizer(0.01),\n",
    "            activation_fn=tf.nn.sigmoid)\n",
    "        self.pred = tf.argmax(self.logits, 1)\n",
    "        self.acc = tf.metrics.accuracy(self.labels, self.pred)\n",
    "        self.loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(\n",
    "            multi_class_labels=self.one_hot_labels, logits=self.logits))\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(\n",
    "            self.hypers['learning_rate'], 0.9)\n",
    "        self.train_op = optimizer.minimize(self.loss)\n",
    "\n",
    "    def _init_sess(self):\n",
    "        self.sess = tf.Session()\n",
    "        init = tf.group(tf.global_variables_initializer(),\n",
    "                        tf.local_variables_initializer())\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        running_loss = None\n",
    "\n",
    "        for i in range(self.hypers['max_iters']):\n",
    "            idx = np.random.randint(0, len(x), self.hypers['batch_size'])\n",
    "            batch_x, batch_y = x[idx], y[idx]\n",
    "            feed_dict = {self.input_data: batch_x, self.labels: batch_y}\n",
    "            l, _ = self.sess.run([self.loss, self.train_op], feed_dict)\n",
    "            if running_loss:\n",
    "                running_loss = 0.99 * running_loss + 0.01 * l\n",
    "            else:\n",
    "                running_loss = l\n",
    "            if i % self.hypers['eval_iters'] == 0:\n",
    "                print('iter: %d running_loss: %.4f' % (i, running_loss))\n",
    "\n",
    "    def score(self, x, y):\n",
    "        feed_dict = {self.input_data: x, self.labels: y}\n",
    "        acc = self.sess.run(self.acc, feed_dict)[1]\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
