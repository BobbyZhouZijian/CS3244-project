{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# RNN architecture using keras and sklearn\n",
    "!pip install sklearn\n",
    "!pip install keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "from keras.layers import Dense, LSTM, BatchNormalization, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# bayes optimization\n",
    "!pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/match_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be removed when the data is cleaned\n",
    "df.drop(columns=['Unnamed: 0', 'MP'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "batch_size = 32\n",
    "epoch = 200\n",
    "input_dim = 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert the input df\n",
    "df = df[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the lstm with all features starting from the open price\n",
    "# still contains the high\n",
    "input_features = data.iloc[::, :-1].values\n",
    "input_data = input_features\n",
    "labels = data.iloc[::, -1].values\n",
    "\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_data[::]\n",
    "y = labels[::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% for as test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],  input_dim, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], input_dim, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, dropout1_rate=0.2, dropout2_rate=0.2, lr=0.0001):\n",
    "    #  reference https://publications.lib.chalmers.se/records/fulltext/250411/250411.pdf\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 256, return_sequences = True, input_shape = input_shape))\n",
    "    model.add(Dropout(dropout1_rate))\n",
    "\n",
    "    model.add(LSTM(units = 256))\n",
    "    model.add(Dropout(dropout2_rate))\n",
    "\n",
    "    model.add(Dense(units = 1))\n",
    "    # model.summary()\n",
    "    return model\n",
    "\n",
    "    # model.compile(optimizer=Adam(lr=lr), loss='mean_squared_error', metrics=['accuracy'])\n",
    "    # model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epoch, batch_size=batch_size)\n",
    "    # model.save('./model_store/LSTM2.model')\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=128, input_shape=(input_dim,)))\n",
    "    model.add(Dense(units=128, activation='relu', activity_regularizer=l2(0.01)))\n",
    "    model.add(Dense(units=128, activation='relu', activity_regularizer=l2(0.01)))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss='mean_squared_error', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epoch, batch_size=batch_size)\n",
    "    '''\n",
    "\n",
    "iter_count = 1\n",
    "\n",
    "def fit_with(input_shape, verbose, dropout1_rate, dropout2_rate, lr):\n",
    "    global iter_count\n",
    "    \n",
    "    # reference https://keras.io/api/callbacks/model_checkpoint/\n",
    "    \n",
    "    # create model\n",
    "    model = get_model(input_shape, dropout1_rate, dropout2_rate, lr)\n",
    "    \n",
    "    # create optimizer using adam\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # setup checkpoints callback\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'./model_store/lstm_checkpoints/checkpoint_{iter_count}',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    iter_count += 1\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "              epochs=epoch, batch_size=batch_size, callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    # evaluate with val dataset\n",
    "    score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "    print(f\"test loss is {score[0]}, test accuracy is {score[1]}\")\n",
    "    \n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "input_shape = (input_dim, 1)\n",
    "fit_with_partial = partial(fit_with, input_shape, verbose)\n",
    "\n",
    "get_model(input_shape=(input_dim, 1))\n",
    "\n",
    "# bayesian optimization\n",
    "pbounds = {'dropout1_rate': (0.1, 0.5), 'dropout2_rate': (0.1, 0.5), 'lr': (1e-4, 1e-2)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f = fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=10,)\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
